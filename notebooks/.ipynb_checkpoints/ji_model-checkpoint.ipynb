{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications import DenseNet121\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "style.use('seaborn-whitegrid')\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this with naming schematic\n",
    "gesture_name = ['wave', 'pointup', 'rockon', 'pointright']\n",
    "\n",
    "gestures = {'wave':'Hello',\n",
    "            'pointup':'Volume_Up',\n",
    "            'rockon':'Play',\n",
    "            'pointright':'Next'}\n",
    "\n",
    "gestures_map = {'Hello' : 0,\n",
    "                'Volume_Up': 1,\n",
    "                'Play': 2,\n",
    "                'Next': 3,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def process_data(X_data, y_data):\n",
    "    X_data = np.array(X_data, dtype = 'float32')\n",
    "    if rgb:\n",
    "        pass\n",
    "    else:\n",
    "        X_data = np.stack((X_data,)*3, axis=-1)\n",
    "    X_data /= 255\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = to_categorical(y_data, num_classes=5)\n",
    "    return X_data, y_data\n",
    "\n",
    "def walk_file_tree(relative_path):\n",
    "    X_data = []\n",
    "    y_data = [] \n",
    "    for directory, subdirectories, files in os.walk(relative_path):\n",
    "        for file in files:\n",
    "            if not file.startswith('.') and (not file.startswith('C_')):\n",
    "                path = os.path.join(directory, file)\n",
    "                gesture_name = gestures[file.split('_')[0]]\n",
    "                y_data.append(gestures_map[gesture_name])\n",
    "                X_data.append(process_image(path))   \n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    X_data, y_data = process_data(X_data, y_data)\n",
    "    return X_data, y_data\n",
    "\n",
    "def augment_data(img_path, train_batch_size, directory, prefix, generation_count):\n",
    "    try:\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255, \n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2) \n",
    "\n",
    "        x = load_img(img_path)\n",
    "        x = img_to_array(x)\n",
    "        x = x.reshape((1, ) + x.shape)\n",
    "\n",
    "        i = 0\n",
    "        for batch in test_datagen.flow(x, batch_size=train_batch_size,\n",
    "                              save_to_dir=directory, save_prefix=prefix, save_format='png'):\n",
    "            i += 1\n",
    "            if i > generation_count:\n",
    "                return 1\n",
    "                break\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "class Data(object):\n",
    "    def __init__(self):\n",
    "        self.X_data = []\n",
    "        self.y_data = []\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.X_data, self.y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rgb = True\n",
    "relative_path = './../../data/'\n",
    "X_data, y_data = walk_file_tree(relative_path)\n",
    "train_batch_size = 64\n",
    "for i in range(4):\n",
    "    img_len = (sum(np.argmax(y_data, axis=1) == i))\n",
    "    for j in range(0, img_len, 10):\n",
    "        img = gesture_name[i]\n",
    "        file_path = '../data/original/' + gesture_name[i] + '_' + str(j) + '.png'\n",
    "        res = augment_data(file_path, train_batch_size, '../../data/aug', gesture_name[i]+'_' + str(j), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_data shape: (5781, 224, 224, 3)\n",
      "y_data shape: (5781, 5)\n"
     ]
    }
   ],
   "source": [
    "rgb = True\n",
    "X_data, y_data = walk_file_tree(relative_path)\n",
    "print(f'X_data shape: {X_data.shape}')\n",
    "print(f'y_data shape: {y_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state=12, stratify=y_data)\n",
    "\n",
    "# train val split with train data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state=12, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prep and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './models/dense_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=file_path, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               restore_best_weights=True)\n",
    "imageSize = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_base = DenseNet121(weights='imagenet', include_top = False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = optimizers.Adam()\n",
    "base_model =  dense_base\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "x = Dense(128, activation='relu', name='fc3')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu', name='fc4')(x)\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "Train on 3699 samples, validate on 925 samples\n",
      "Epoch 1/3\n",
      "3699/3699 [==============================] - 230s 62ms/step - loss: 0.4354 - accuracy: 0.8956 - val_loss: 0.4167 - val_accuracy: 0.9103\n",
      "Epoch 2/3\n",
      "3699/3699 [==============================] - 222s 60ms/step - loss: 0.0432 - accuracy: 0.9892 - val_loss: 0.1208 - val_accuracy: 0.9708\n",
      "Epoch 3/3\n",
      "3456/3699 [===========================>..] - ETA: 11s - loss: 0.0118 - accuracy: 0.9962"
     ]
    }
   ],
   "source": [
    "# Train top layers only\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)]\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"training\")\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=train_batch_size, validation_data=(X_val, y_val), verbose=1, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# plots the model \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('./../results/Dense_Loss.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "y_test_bool = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(classification_report(y_test_bool, y_pred_bool))\n",
    "print(confusion_matrix(y_test_bool, y_pred_bool))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
