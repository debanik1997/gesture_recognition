{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import cv2\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from keras import models, layers, optimizers\n",
    "from keras.applications import VGG16\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "% matplotlib inline\n",
    "style.use('seaborn-whitegrid')\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this with naming schematic\n",
    "gestures = {'wave':'Hello',\n",
    "            'pointup':'Volume_Up',\n",
    "            'rockon':'Play',\n",
    "            'pointright':'Next'}\n",
    "\n",
    "gestures_map = {'Hello' : 0,\n",
    "                'Volume_Up': 1,\n",
    "                'Play': 2,\n",
    "                'Next': 3,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((224, 224))\n",
    "    img = np.array(img)\n",
    "    return img\n",
    "\n",
    "def process_data(X_data, y_data):\n",
    "    X_data = np.array(X_data, dtype = 'float32')\n",
    "    if rgb:\n",
    "        pass\n",
    "    else:\n",
    "        X_data = np.stack((X_data,)*3, axis=-1)\n",
    "    X_data /= 255\n",
    "    y_data = np.array(y_data)\n",
    "    y_data = to_categorical(y_data, num_classes=5)\n",
    "    return X_data, y_data\n",
    "\n",
    "def walk_file_tree(relative_path):\n",
    "    X_data = []\n",
    "    y_data = [] \n",
    "    for directory, subdirectories, files in os.walk(relative_path):\n",
    "        for file in files:\n",
    "            if not file.startswith('.') and (not file.startswith('C_')):\n",
    "                path = os.path.join(directory, file)\n",
    "                gesture_name = gestures[file.split('_')[0]]\n",
    "                y_data.append(gestures_map[gesture_name])\n",
    "                X_data.append(process_image(path))   \n",
    "\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    X_data, y_data = process_data(X_data, y_data)\n",
    "    return X_data, y_data\n",
    "\n",
    "class Data(object):\n",
    "    def __init__(self):\n",
    "        self.X_data = []\n",
    "        self.y_data = []\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.X_data, self.y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path = './data_creation/data/'\n",
    "rgb = True\n",
    "X_data, y_data = walk_file_tree(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette = Data()\n",
    "silhouette.X_data, silhouette.y_data = walk_file_tree(relative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_data shape: {X_data.shape}')\n",
    "print(f'y_data shape: {y_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_rgb, X_test_rgb, y_train_rgb, y_test_rgb = train_test_split(image_rgb, y_data, test_size = 0.2, random_state=12, stratify=y_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state=12, stratify=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './models/temp_model.h5'\n",
    "model_checkpoint = ModelCheckpoint(filepath=file_path, save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "                               min_delta=0,\n",
    "                               patience=10,\n",
    "                               verbose=1,\n",
    "                               mode='auto',\n",
    "                               restore_best_weights=True)\n",
    "imageSize = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = optimizers.Adam()\n",
    "\n",
    "base_model = vgg_base  # Topless\n",
    "# Add top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "x = Dense(128, activation='relu', name='fc3')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu', name='fc4')(x)\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Train top layers only\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=1)]\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_train, y_train), verbose=1,\n",
    "          callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VGG16\n",
    "# Get back the convolutional part of a VGG network trained on ImageNet\n",
    "\n",
    "imageSize = 224\n",
    "model1 = VGG16(weights='imagenet', include_top=False, input_shape=(imageSize, imageSize, 3))\n",
    "optimizer1 = optimizers.Adam()\n",
    "\n",
    "base_model = model1  # Topless\n",
    "# Add top layer\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', name='fc1')(x)\n",
    "x = Dense(128, activation='relu', name='fc2')(x)\n",
    "x = Dense(128, activation='relu', name='fc3')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu', name='fc4')(x)\n",
    "\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Train top layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_train, y_train), verbose=1,\n",
    "          callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/new_temp.h5')\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('/Users/jipak/gesture_recognition/models/new_temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_metrics(X_test, y_test):\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    print(confusion_matrix(y_true, pred))\n",
    "    print('\\n')\n",
    "    print(classification_report(y_true, pred))\n",
    "get_classification_metrics(X_data, y_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
